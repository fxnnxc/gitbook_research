# Multiple Descent: Design Your Own Generalization Curve

### Preliminaries&#x20;

> Classical statistical learning theory supports a U-shaped curve of generalization versus model complexity -> #1. Introduction&#x20;
>
>
>
> 기본적으로 Generalization Error는 모델사이즈에 대해서 U자형태를 띈다 .       &#x20;



> the test error decreases again once model complexity grows beyond the interpolation threshold, resulting in the so called double-descent phenomenon  #1. Introduction&#x20;
>
>
>
> 딥러닝모델은 기본적으로  Deoowe  &#x20;





### Key messages

> For a fixed family of models, a common way to select a model from this family is through empirical risk minimization   # 1. Introduction&#x20;
>
> \-> /

> Indeed, in this paper we show how to construct a model family for which the generalization curve can be fully controlled  # 1. Introduction&#x20;



